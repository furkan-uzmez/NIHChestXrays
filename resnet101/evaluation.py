import matplotlib.pyplot as plt
import torch
from tqdm import tqdm  
from sklearn.metrics import (
    precision_score, recall_score, f1_score,
    roc_curve, auc ,confusion_matrix
)
import torch.nn.functional as F
import seaborn as sns
import numpy as np

def plot_results(train_losses, train_accuracies, val_losses, val_accuracies):
    epochs = range(1, len(train_losses) + 1)
    
    plt.figure(figsize=(12, 5))

    # --- Loss Plot ---
    plt.subplot(1, 2, 1)
    plt.plot(epochs, train_losses, marker='o', label='Train Loss')
    plt.plot(epochs, val_losses, marker='s', label='Validation Loss')
    plt.title("Epoch vs Loss")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()

    # --- Accuracy Plot ---
    plt.subplot(1, 2, 2)
    plt.plot(epochs, train_accuracies, marker='o', label='Train Accuracy')
    plt.plot(epochs, val_accuracies, marker='s', label='Validation Accuracy')
    plt.title("Epoch vs Accuracy")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.legend()

    plt.tight_layout()
    plt.show()

    # --- Train Loss ---
    plt.figure(figsize=(6, 4))
    plt.plot(epochs, train_losses, marker='o', color='blue', label='Train Loss')
    plt.title("Train Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # --- Validation Loss ---
    plt.figure(figsize=(6, 4))
    plt.plot(epochs, val_losses, marker='o', color='red', label='Validation Loss')
    plt.title("Validation Loss per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # --- Train Accuracy ---
    plt.figure(figsize=(6, 4))
    plt.plot(epochs, train_accuracies, marker='o', color='green', label='Train Accuracy')
    plt.title("Train Accuracy per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()

    # --- Validation Accuracy ---
    plt.figure(figsize=(6, 4))
    plt.plot(epochs, val_accuracies, marker='o', color='orange', label='Validation Accuracy')
    plt.title("Validation Accuracy per Epoch")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.grid(True)
    plt.legend()
    plt.tight_layout()
    plt.show()



def eval_on_metrics(model, test_loader):
    model.eval()
    device = next(model.parameters()).device

    y_true = []
    y_pred = []
    y_scores = []

    with torch.no_grad():
        for images, labels in tqdm(test_loader, desc="Evaluating"):
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)  # shape: [batch_size, num_classes]
            probs = F.softmax(outputs, dim=1)  # olasılıkları al
            preds = torch.argmax(probs, dim=1)  # en yüksek olasılık sınıfı

            y_true.extend(labels.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())
            y_scores.extend(probs[:, 1].cpu().numpy())  # Pozitif sınıfın olasılık skoru (1.sınıf)

    # 5. Compute metrics
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)

    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    roc_auc = auc(fpr, tpr)

    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    print(f"AUC:       {roc_auc:.4f}")

    # 6. Plot ROC Curve
    plt.figure(figsize=(6, 6))
    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')
    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title("Receiver Operating Characteristic on Test Data")
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.show()

    # 7. Confusion Matrix
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix on Test Data")
    plt.show()
